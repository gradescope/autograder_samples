}
thirdMomentY <- function(f){
meanY(f)^3 + 3*meanY(f)*varY(f)
}
# things that will different approximations of average log wealth
thirdOrder <- function(f){
meanY(f) - .5*secMomentY(f) + thirdMomentY(f)/3
}
secondOrder <- function(f){
meanY(f) - .5*secMomentY(f)
}
secondOrderApprox <- function(f){
meanY(f) - .5*varY(f)
}
#plot
d <- data.frame(f, thirdOrder(f), secondOrder(f), secondOrderApprox(f))
plot(d[,1],d[,2], type = "l", ylim = c(0,max(d)), col = "green")
lines(d[,1], d[,3], col = "red")
lines(d[,1], d[,4], col = "blue")
abline(v = (mu-r)/sigma/sigma)
#plot
d <- data.frame(f, thirdOrder(f), secondOrder(f), secondOrderApprox(f))
r <- .0000001
plot(d[,1],d[,2], type = "l", ylim = c(0,max(d)), col = "green")
d[,2]
plot.ts(d)
periodReturn(SPY)
head(SPY)
?periodReturn(SPY)
periodReturn(SPY, period='daily')
r <- .0000001
mu <- mean(coredata(periodReturn(SPY, period='daily')))
sigma <- sd(coredata(periodReturn(SPY, period='daily')))
f <- seq(.01, 1.5, .01)
meanY <- function(f){
f*mu
}
varY <- function(f){
f*f*sigma*sigma
}
secMomentY <- function(f){
varY(f) + (meanY(f))^2
}
thirdMomentY <- function(f){
meanY(f)^3 + 3*meanY(f)*varY(f)
}
# things that will different approximations of average log wealth
thirdOrder <- function(f){
meanY(f) - .5*secMomentY(f) + thirdMomentY(f)/3
}
secondOrder <- function(f){
meanY(f) - .5*secMomentY(f)
}
secondOrderApprox <- function(f){
meanY(f) - .5*varY(f)
}
#plot
d <- data.frame(f, thirdOrder(f), secondOrder(f), secondOrderApprox(f))
plot(d[,1],d[,2], type = "l", ylim = c(0,max(d)), col = "green")
lines(d[,1], d[,3], col = "red")
lines(d[,1], d[,4], col = "blue")
head(d)
max(d)
plot(d[,1],d[,2], type = "l", ylim = c(0,max(d[,-1])), col = "green")
lines(d[,1], d[,3], col = "red")
lines(d[,1], d[,4], col = "blue")
periodReturn(SPY, period='daily')
mean(periodReturn(SPY, period='daily'))
min(periodReturn(SPY, period='daily'))
hist(periodReturn(SPY, period='daily'))
mean(1+periodReturn(SPY, period='daily'))
f <- seq(.01, 2.5, .01)
meanY <- function(f){
f*mu
}
varY <- function(f){
f*f*sigma*sigma
}
secMomentY <- function(f){
varY(f) + (meanY(f))^2
}
thirdMomentY <- function(f){
meanY(f)^3 + 3*meanY(f)*varY(f)
}
# things that will different approximations of average log wealth
thirdOrder <- function(f){
meanY(f) - .5*secMomentY(f) + thirdMomentY(f)/3
}
secondOrder <- function(f){
meanY(f) - .5*secMomentY(f)
}
secondOrderApprox <- function(f){
meanY(f) - .5*varY(f)
}
#plot
d <- data.frame(f, thirdOrder(f), secondOrder(f), secondOrderApprox(f))
plot(d[,1],d[,2], type = "l", ylim = c(0,max(d[,-1])), col = "green")
lines(d[,1], d[,3], col = "red")
lines(d[,1], d[,4], col = "blue")
abline(v = (mu-r)/sigma/sigma)
abline(v = (mu)/sigma/sigma, col = "red")
abline(v = , )
abline(v = mu/(mu^2+sigma^2), col = "blue")
mean(1+periodReturn(SPY, period='daily'))
mu/(mu^2+sigma^2)
(mu)/sigma/sigma
cat((mu)/sigma/sigma)
d <- read.csv("~/spy_strategy/data/spy_data.csv")
head(d)
plot.ts(d$ask_close)
setwd("~/gradescopeR/")
# load in the package
library(gradeR)
# set working directory to place where you have
# a. your grading file with the tests
# b. all external .csv files that students use for their assignment
setwd("~/gradescopeR/autograding_code_and_data/")
# this is the directory with all of the student submissions
submissionDir <- "../example_submissions/"
# get the grades
calcGrades(submission_dir = submissionDir,
your_test_file = "assignment1_grading_file.r")
list.files()
list.files("../example_submissions/")
submission_file <- "../example_submissions/jane_doe_hw1_submission.r"
test_file <- "assignment1_grading_file.r"
if(missing(submission_file) | missing(test_file))
stop("the first two arguments are required")
number_questions <- length(testthat::test_file(test_file, reporter = "minimal"))
if(number_questions == 0)
stop("you need at least one graded question")
# run student's submission in a separate environment
tmp_full_path <- paste(submission_dir, path, sep = "")
testEnv <- new.env()
# run student's submission in a separate environment
testEnv <- new.env()
# source each assignment
tryCatch({
source(tmp_full_path, testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
}, warning = function(w){
cat("Produced a warning: ", path, "\n")
message(w)
cat("\n")
})
rm(submissionDir)
# source each assignment
tryCatch({
source(submission_file, testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
}, warning = function(w){
cat("Produced a warning: ", path, "\n")
message(w)
cat("\n")
})
# test the student's submissions
lr <- testthat::ListReporter$new()
out <- testthat::test_file(test_file, reporter = lr, env = testEnv)
lr$results$as_list()
length(lr$results$as_list())
lr$results$as_list()[[1]]
results <- lr$results$as_list()
methods::is
?methods::is
results[[1]]
results[[1]]$results
results[[1]]$results[[1]]
class(results[[1]]$results[[1]])
which_filename <- "testing"
if(!which_filename %in% c("gradescope", "testing"))
stop("argument which_filename incorrectly specified")
which_filename %in% c("gradescope", "testing")
?%in%
?`%in%``
``
?`%in%`
submission_file <- ifelse(which_filename == "gradescope", "/autograder/results/results.json", "results.json")
if(missing(test_file))
stop("must have a test file")
test_file <- "assignment1_grading_file.r"
# TODO: add this to the other function
number_tests <- length(testthat::test_file(test_file, reporter = "minimal"))
if(number_tests == 0)
stop("you need at least one graded question")
# run student's submission in a separate environment
testEnv <- new.env()
# source each assignment
tryCatch({
source(submission_file, testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
}, warning = function(w){
cat("Produced a warning: ", path, "\n")
message(w)
cat("\n")
})
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
submission_file <- "../example_submissions/jane_doe_hw1_submission.r"
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# source each assignment
tryCatch(source("derp", testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# test the student's submissions
lr <- testthat::ListReporter$new()
out <- testthat::test_file(test_file, reporter = lr, env = testEnv)
tests <- list()
?tryCatch
setwd("~/r_autograde_gradescope/")
filename <- "ps1.R" # Assignment file name
json.filename <- "results.json"# "/autograder/results/results.json" # Change to "results.json" when testing locally
suppressMessages(library(tidyverse))
suppressMessages(library(jsonlite))
library(gapminder)
library(tidyverse)
factors.to.chars <- function(column){
if("factor" %in% class(column)){
as.character(column)
}else{
column
}
}
my.toString <- function(obj){
if("data.frame" %in% class(obj)){
toString(as_tibble(lapply(obj, as.character)))
}else{
toString(obj)
}
}
my.gap.1 <- tibble(country = c("countr1", "countr2", "countr1", "countr2"),
continent = c("cont1", "cont2", "cont1", "cont2"),
year = c(1, 1, 2, 2),
lifeExp = c(70, 71, 76, 50),
pop = c(30, 20, 32, 21),
gdpPercap =c(40, 50, 42, 52))
my.gap.2 <- tibble(country = c("countr1", "countr2", "countr1", "countr2"),
continent = c("cont2", "cont1", "cont2", "cont1"),
year = c(1, 1, 2, 2),
lifeExp = c(70, 71, 76, 50),
pop = c(30, 20, 32, 21),
gdpPercap =c(40, 50, 42, 52))
test.cases <- list(
list(
name = "Continents sorted",
fun = "continents.gdp",
args = list(my.gap.1, 2),
expect = data.frame(continent = c("cont1", "cont2"), gdp = c(32*42, 21*52)),
visibility = "visible",
weight = 10
),
list(
name = "Continents not sorted",
fun = "continents.gdp",
args = list(my.gap.2, 2),
expect = data.frame(continent = c("cont1", "cont2"), gdp = c(21*52, 32*42)),
visibility = "hidden",
weight = 10
)
)
ret <- tryCatch(source(filename), error = function(c) c, warning = function(c) c ,message = function(c) c)
ret
filename
names(ret)
"visible" %in% names(ret)
setwd("~/gradescopeR/")
setwd("./autograding_code_and_data/")
submission_file <- "../example_submissions/jane_doe_hw1_submission.r"
test_file <- "assignment1_grading_file.r"
which_results <- "testing"
if(!(results %in% c("gradescope", "testing")))
stop("argument which_filename incorrectly specified")
json_filename <- ifelse(which_results == "gradescope", "/autograder/results/results.json", "results.json")
if(!(which_results %in% c("gradescope", "testing")))
stop("argument which_filename incorrectly specified")
json_filename <- ifelse(which_results == "gradescope", "/autograder/results/results.json", "results.json")
if(missing(test_file))
stop("must have a test file")
# TODO: add this to the other function
number_tests <- length(testthat::test_file(test_file, reporter = "minimal"))
if(number_tests == 0)
stop("you need at least one graded question")
# run student's submission in a separate environment
testEnv <- new.env()
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# test the student's submissions
lr <- testthat::ListReporter$new()
out <- testthat::test_file(test_file, reporter = lr, env = testEnv)
tests <- list()
raw_results <- lr$results$as_list()
raw_results[[i]]
i <- 1
raw_results[[i]]
raw_results[[i]]%test
raw_results[[i]]$test
raw_results[[1]]
cur.name <- raw_results[[i]]$test
cur.name
derpyname <- "first (visible)"
?grepl
grepl("\(visible\)", derpyname)
grepl("\\(visible\\)", derpyname)
derpyname
derpyname <- "first (invisible)"
derpyname
grepl("\\(visible\\)", derpyname)
calcGradesForGradescope <- function(submission_file, test_file, which_results){
if(!(which_results %in% c("gradescope", "testing")))
stop("argument which_filename incorrectly specified")
json_filename <- ifelse(which_results == "gradescope", "/autograder/results/results.json", "results.json")
if(missing(test_file))
stop("must have a test file")
# TODO: add this to the other function
number_tests <- length(testthat::test_file(test_file, reporter = "minimal"))
if(number_tests == 0)
stop("you need at least one graded question")
# run student's submission in a separate environment
testEnv <- new.env()
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# test the student's submissions
# for the time being, each test is worth one point
lr <- testthat::ListReporter$new()
out <- testthat::test_file(test_file, reporter = lr, env = testEnv)
tests <- list()
raw_results <- lr$results$as_list()
for(i in seq_along(number_tests)){
test_name <- raw_results[[i]]$test
test_visibility <- ifelse(grepl("\\(visible\\)", cur.name), "visible", "hidden") # search for the exact phrase (visible)
test_max_score <- 1 # TODO generalize
test_score <- ifelse(methods::is(lr$results$as_list()[[q]]$results[[1]], "expectation_success"), 1, 0)
tests[["tests"]][i] <- list(name = test_name,
score = test_score,
max_score = test_max_score,
visibility = test_visibility)
}
# now write out all the stuff to a json file
write(toJSON(tests, auto_unbox = T), file = json_filename)
}
# set working directory to place where you have
# a. your grading file with the tests
# b. all external .csv files that students use for their assignment
setwd("~/gradescopeR/autograding_code_and_data/")
# this is the directory with all of the student submissions
submissionDir <- "../example_submissions/"
calcGradesForGradescope("../example_submissions/jane_doe_hw1_submission.r",
)
calcGradesForGradescope("../example_submissions/jane_doe_hw1_submission.r",
"assignment1_grading_file.r",
"test")
calcGradesForGradescope("../example_submissions/jane_doe_hw1_submission.r",
"assignment1_grading_file.r",
"testing")
calcGradesForGradescope <- function(submission_file, test_file, which_results){
if(!(which_results %in% c("gradescope", "testing")))
stop("argument which_filename incorrectly specified")
json_filename <- ifelse(which_results == "gradescope", "/autograder/results/results.json", "results.json")
if(missing(test_file))
stop("must have a test file")
# TODO: add this to the other function
number_tests <- length(testthat::test_file(test_file, reporter = "minimal"))
if(number_tests == 0)
stop("you need at least one graded question")
# run student's submission in a separate environment
testEnv <- new.env()
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# test the student's submissions
# for the time being, each test is worth one point
lr <- testthat::ListReporter$new()
out <- testthat::test_file(test_file, reporter = lr, env = testEnv)
tests <- list()
raw_results <- lr$results$as_list()
for(i in seq_along(number_tests)){
test_name <- raw_results[[i]]$test
test_visibility <- ifelse(grepl("\\(visible\\)", test_name), "visible", "hidden") # search for the exact phrase (visible)
test_max_score <- 1 # TODO generalize
test_score <- ifelse(methods::is(lr$results$as_list()[[q]]$results[[1]], "expectation_success"), 1, 0)
tests[["tests"]][i] <- list(name = test_name,
score = test_score,
max_score = test_max_score,
visibility = test_visibility)
}
# now write out all the stuff to a json file
write(toJSON(tests, auto_unbox = T), file = json_filename)
}
calcGradesForGradescope("../example_submissions/jane_doe_hw1_submission.r",
"assignment1_grading_file.r",
"testing")
calcGradesForGradescope <- function(submission_file, test_file, which_results){
if(!(which_results %in% c("gradescope", "testing")))
stop("argument which_filename incorrectly specified")
json_filename <- ifelse(which_results == "gradescope", "/autograder/results/results.json", "results.json")
if(missing(test_file))
stop("must have a test file")
# TODO: add this to the other function
number_tests <- length(testthat::test_file(test_file, reporter = "minimal"))
if(number_tests == 0)
stop("you need at least one graded question")
# run student's submission in a separate environment
testEnv <- new.env()
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# test the student's submissions
# for the time being, each test is worth one point
lr <- testthat::ListReporter$new()
out <- testthat::test_file(test_file, reporter = lr, env = testEnv)
tests <- list()
raw_results <- lr$results$as_list()
for(i in seq_along(number_tests)){
test_name <- raw_results[[i]]$test
test_visibility <- ifelse(grepl("\\(visible\\)", test_name), "visible", "hidden") # search for the exact phrase (visible)
test_max_score <- 1 # TODO generalize
test_score <- ifelse(methods::is(raw_results[[i]]$results[[1]], "expectation_success"), 1, 0)
tests[["tests"]][i] <- list(name = test_name,
score = test_score,
max_score = test_max_score,
visibility = test_visibility)
}
# now write out all the stuff to a json file
write(toJSON(tests, auto_unbox = T), file = json_filename)
}
calcGradesForGradescope("../example_submissions/jane_doe_hw1_submission.r",
"assignment1_grading_file.r",
"testing")
calcGradesForGradescope <- function(submission_file, test_file, which_results){
if(!(which_results %in% c("gradescope", "testing")))
stop("argument which_filename incorrectly specified")
json_filename <- ifelse(which_results == "gradescope", "/autograder/results/results.json", "results.json")
if(missing(test_file))
stop("must have a test file")
# TODO: add this to the other function
number_tests <- length(testthat::test_file(test_file, reporter = "minimal"))
if(number_tests == 0)
stop("you need at least one graded question")
# run student's submission in a separate environment
testEnv <- new.env()
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# test the student's submissions
# for the time being, each test is worth one point
lr <- testthat::ListReporter$new()
out <- testthat::test_file(test_file, reporter = lr, env = testEnv)
tests <- list()
tests[["tests"]] <- list()
raw_results <- lr$results$as_list()
for(i in seq_along(number_tests)){
test_name <- raw_results[[i]]$test
test_visibility <- ifelse(grepl("\\(visible\\)", test_name), "visible", "hidden") # search for the exact phrase (visible)
test_max_score <- 1 # TODO generalize
test_score <- ifelse(methods::is(raw_results[[i]]$results[[1]], "expectation_success"), 1, 0)
tests[["tests"]][i] <- list(name = test_name,
score = test_score,
max_score = test_max_score,
visibility = test_visibility)
}
# now write out all the stuff to a json file
write(toJSON(tests, auto_unbox = T), file = json_filename)
}
calcGradesForGradescope("../example_submissions/jane_doe_hw1_submission.r",
"assignment1_grading_file.r",
"testing")
calcGradesForGradescope <- function(submission_file, test_file, which_results){
if(!(which_results %in% c("gradescope", "testing")))
stop("argument which_filename incorrectly specified")
json_filename <- ifelse(which_results == "gradescope", "/autograder/results/results.json", "results.json")
if(missing(test_file))
stop("must have a test file")
# TODO: add this to the other function
number_tests <- length(testthat::test_file(test_file, reporter = "minimal"))
if(number_tests == 0)
stop("you need at least one graded question")
# run student's submission in a separate environment
testEnv <- new.env()
# source each assignment
tryCatch(source(submission_file, testEnv),  error = function(c) c, warning = function(c) c ,message = function(c) c)
# test the student's submissions
# for the time being, each test is worth one point
lr <- testthat::ListReporter$new()
out <- testthat::test_file(test_file, reporter = lr, env = testEnv)
tests <- list()
tests[["tests"]] <- list()
raw_results <- lr$results$as_list()
for(i in seq_along(number_tests)){
test_name <- raw_results[[i]]$test
test_visibility <- ifelse(grepl("\\(visible\\)", test_name), "visible", "hidden") # search for the exact phrase (visible)
test_max_score <- 1 # TODO generalize
test_score <- ifelse(methods::is(raw_results[[i]]$results[[1]], "expectation_success"), 1, 0)
tests[["tests"]][[i]] <- list(name = test_name,
score = test_score,
max_score = test_max_score,
visibility = test_visibility)
}
# now write out all the stuff to a json file
write(toJSON(tests, auto_unbox = T), file = json_filename)
}
calcGradesForGradescope("../example_submissions/jane_doe_hw1_submission.r",
"assignment1_grading_file.r",
"testing")
